{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AaayaB4/ADL/blob/Exercises/Excercise5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "_Q-KRsLb5PDH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.src.regularizers import l2\n",
        "from keras.src.utils import load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Iir8PRKs5PDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fdfe4d-8451-49d4-e4c9-8649c0c3dd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Data loading and train/test split\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tUR9MGIa5PDM"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding for the predicted label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FdToEgC_5PDN"
      },
      "outputs": [],
      "source": [
        "#  Model creation and fitting\n",
        "model_cifar = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "S0O9fzdX5PDO"
      },
      "source": [
        "I incorporated two convolutional layers into the input image, employing 32 filters with dimensions of 3x3 for each layer. I selected the ReLU activation function for these layers. The 'he_uniform' parameter is used to initialize the weights, ensuring that gradient scales remain relatively uniform across all layers. Furthermore, by utilizing 'Same' padding, the output size is kept equal to the input size. The model is designed to accept input images with dimensions of 32x32 pixels and a three-channel color format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K6N89-qs5PDO"
      },
      "outputs": [],
      "source": [
        "model_cifar.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model_cifar.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "76Ivh0-L5PDP"
      },
      "outputs": [],
      "source": [
        "model_cifar.add(MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tOtP6Htl5PDP"
      },
      "source": [
        "Transforming the input into a one-dimensional tensor to enable compatibility with the dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L0hrDmXn5PDP"
      },
      "outputs": [],
      "source": [
        "model_cifar.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0NEayHBy5PDP"
      },
      "outputs": [],
      "source": [
        "model_cifar.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "IE9d7eMI5PDP"
      },
      "source": [
        "Incorporating dropout, which helps mitigate overfitting by randomly setting 50% of the input units to 0 during each training update.\n",
        "Introducing a fully connected layer responsible for learning patterns, with the application of L2 regularization to the weights to further reduce overfitting.\n",
        "The final layer produces a probability distribution across 10 classes, where each neuron corresponds to a class.\n",
        "I employed the 'Softmax' activation function, ensuring that the probabilities add up to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DdmG14YM5PDQ"
      },
      "outputs": [],
      "source": [
        "model_cifar.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model_cifar.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LR_xpsh45PDQ"
      },
      "source": [
        "Compiling the model by utilizing the Adam optimizer and categorical cross-entropy as the loss function, given that this is a multi-class classification problem. Proceeding to fit the model with 10 epochs to ensure that the training process doesn't excessively extend in duration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "61WWAVkf5PDQ"
      },
      "outputs": [],
      "source": [
        "model_cifar.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJwRVmsJ5PDQ",
        "outputId": "d8b3471e-7cdb-4588-9fea-3af8afb384d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0261 - accuracy: 0.2951 - val_loss: 1.9066 - val_accuracy: 0.3396\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8596 - accuracy: 0.3573 - val_loss: 1.8214 - val_accuracy: 0.3842\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7192 - accuracy: 0.4163 - val_loss: 1.6370 - val_accuracy: 0.4304\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5614 - accuracy: 0.4811 - val_loss: 1.4784 - val_accuracy: 0.5182\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4185 - accuracy: 0.5376 - val_loss: 1.3922 - val_accuracy: 0.5431\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3463 - accuracy: 0.5711 - val_loss: 1.3396 - val_accuracy: 0.5694\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2862 - accuracy: 0.5956 - val_loss: 1.3811 - val_accuracy: 0.5678\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2577 - accuracy: 0.6155 - val_loss: 1.3572 - val_accuracy: 0.5979\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2130 - accuracy: 0.6403 - val_loss: 1.2912 - val_accuracy: 0.6256\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1635 - accuracy: 0.6616 - val_loss: 1.2474 - val_accuracy: 0.6377\n"
          ]
        }
      ],
      "source": [
        "fit = model_cifar.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4qrGnBta5PDR"
      },
      "source": [
        "# **Feeding the network the dog picture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Eod-jK7k5PDR"
      },
      "source": [
        "Loading the image and standardizing it to match the normalization applied to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6_vV0JQ25PDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e81ee14-ab19-42a5-b6c7-283bd6ae939d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class for base image: cat\n",
            "Predicted class for horizontal flip: cat\n",
            "Predicted class for vertical flip: cat\n"
          ]
        }
      ],
      "source": [
        "image_base = load_img('/content/dog.jpg.png', target_size=(32, 32))\n",
        "image_base = img_to_array(image_base)\n",
        "image_base /= 255.0\n",
        "image_base = np.expand_dims(image_base, axis=0)\n",
        "\n",
        "horizontal_flip = image_base[:, ::-1, :]\n",
        "vertical_flip = image_base[::-1, :, :]\n",
        "\n",
        "prediction_base = model_cifar.predict(image_base)\n",
        "prediction_horizontal = model_cifar.predict(horizontal_flip)\n",
        "prediction_vertical = model_cifar.predict(vertical_flip)\n",
        "\n",
        "predicted_base = np.argmax(prediction_base, axis=1)\n",
        "predicted_horizontal = np.argmax(prediction_horizontal, axis=1)\n",
        "predicted_vertical = np.argmax(prediction_vertical, axis=1)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(f'Predicted class for base image: {class_names[predicted_base[0]]}')\n",
        "print(f'Predicted class for horizontal flip: {class_names[predicted_horizontal[0]]}')\n",
        "print(f'Predicted class for vertical flip: {class_names[predicted_vertical[0]]}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}